#!/usr/bin/env python3
import requests
import re
import urllib.parse as urlparse


target_url = input("Enter the target url\n>")
external_links=[]
target_links=[]
target = target_url.strip(".com")

class bcolors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'


def request(url):
	try:
		return requests.get("http://" + url)
		print(get_response)
	except requests.exceptions.ConnectionError:
		pass


def extract_links_from(url):
    response = request(str(target_url))
    return re.findall('(?:href=")(.*?)"',response.content.decode(errors="ignore"))


def crawl(url):
    href_links=extract_links_from(url)
    for link in href_links:
        link=urlparse.urljoin(url,link)

        if "#" in link:
            link.split("#")[0]

        if target_url in link and link not in target_links:
            target_links.append(link)
            print(link)
            crawl(link)


crawl(target_url)


for link in target_links:
    print(link)
for link in external_links:
    print(link)