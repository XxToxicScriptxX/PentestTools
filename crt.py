#!/usr/bin/env python3
import requests
import re
import urllib.parse as urlparse

target_url = input("Enter the target url\n>")
external_links=[]
target_links=[]
target = target_url.strip(".com")


def request(url):
    try:
        return requests.get(f'https://crt.sh/?Identity=%.{url}')
        print(get_response)
    except requests.exceptions.ConnectionError:
        pass

def extract_links_from(host):
    response = request(str(target_url))
    return re.findall('(?:href=")(.*?)"',response.content.decode(errors="ignore"))

def crawl(url):
    href_links=extract_links_from(url)
    for link in href_links:
        link=urlparse.urljoin(url,link)

        if "#" in link:
            link.split("#")[0]

        if target_url in link and link not in target_links:
            target_links.append(link)
            print(link)



print(request("google.com"))

crawl("google.com")


for link in target_links:
    print(link)
for link in external_links:
    print(link)
